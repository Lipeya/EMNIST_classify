{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RESNET",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lipeya/EMNIST_classify/blob/main/RESNET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train 데이터 처리"
      ],
      "metadata": {
        "id": "wsgpqLwAZmZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D,Conv1D, MaxPooling2D, MaxPooling1D, Dropout, Flatten\n",
        "from keras import losses\n",
        "from keras import optimizers\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "import math"
      ],
      "metadata": {
        "id": "7i310tjpJ0X0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#google drive 연동\n",
        "from google.colab import drive\n",
        "drive.mount('/content/mnt')"
      ],
      "metadata": {
        "id": "vFffwTYY_h5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_array = ['a', 'b','c', 'd', 'e', 'f', 'g', 'h', 'i','j','k','l','m','n','o','p', 'q', 'r','s', 't','u','v','w','x','y','z']\n",
        "class_dict = {'a':0, 'b':1,'c':2, 'd':3, 'e':4, 'f':5, 'g':6, 'h':7, 'i':8,'j':9,'k':10,'l':11,'m':12,'n':13,'o':14,'p':15, 'q':16, 'r':17,'s':18, 't':19,'u':20,'v':21,'w':22,'x':23,'y':24,'z':25}\n",
        "class_size =len(class_array)\n",
        "print(class_size)"
      ],
      "metadata": {
        "id": "ujO_SNua_eM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_data_list = pd.read_csv(\"/content/mnt/MyDrive/project/emnist-letters-train.csv\") #,chunksize = 100000)\n",
        "test_data_list = pd.read_csv(\"/content/mnt/MyDrive/project/emnist-letters-test.csv\")\n",
        "predict_data_list = pd.read_csv(\"/content/mnt/MyDrive/project/predict_char.csv\")\n",
        "predict_train = pd.read_csv(\"/content/mnt/MyDrive/project/encodedpdc.csv\")\n",
        "predict_test = pd.read_csv(\"/content/mnt/MyDrive/project/encodedpdctest.csv\")\n"
      ],
      "metadata": {
        "id": "um2Qvyr-J1k0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data =  np.array(train_data_list.iloc[:,1:])\n",
        "train_data = train_data.reshape(train_data.shape[0],28,28,1)\n",
        "train_data_class = np.array(train_data_list.iloc[:,0])\n",
        "train_data_class = train_data_class - 1\n",
        "origin_tdc = train_data_class\n",
        "train_data_class = np_utils.to_categorical(train_data_class ,26)"
      ],
      "metadata": {
        "id": "QRAtlGLm_8fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LSTMX\n",
        "import tensorflow as tf\n",
        "input = tf.keras.Input(shape=(28,28,1))\n",
        "efnet = tf.keras.applications.ResNet50(weights=None,\n",
        "                                             include_top = False, \n",
        "                                             input_tensor = input)\n",
        "# Now that we apply global max pooling.\n",
        "gap = tf.keras.layers.GlobalMaxPooling2D()(efnet.output)\n",
        "gap = Dropout(0.2)(gap)\n",
        "gap = Dense(52, activation = 'relu')(gap)\n",
        "gap = Dropout(0.2)(gap)\n",
        "# Finally, we add a classification layer.\n",
        "output = tf.keras.layers.Dense(class_size, activation='softmax')(gap)\n",
        "\n",
        "# bind all\n",
        "func_model = tf.keras.Model(efnet.input, output)\n",
        "func_model.compile(\n",
        "          loss  = tf.keras.losses.CategoricalCrossentropy(),\n",
        "          metrics = tf.keras.metrics.CategoricalAccuracy(),\n",
        "          optimizer = tf.keras.optimizers.Adam())"
      ],
      "metadata": {
        "id": "IkvcMKbZgQ6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LSTMO\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, Input, TimeDistributed, Dropout, concatenate, Bidirectional, LSTM, Conv2D, Dense, MaxPooling2D, Flatten\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.initializers import RandomUniform\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "char_inputs = Input(shape=(class_size,),dtype='float', name='char_predicts_input')\n",
        "predict = Dense(52, activation = 'relu')(char_inputs)\n",
        "predict = Dropout(0.2)(predict)\n",
        "input = tf.keras.Input(shape=(28,28,1))\n",
        "efnet = tf.keras.applications.ResNet50(weights=None,\n",
        "                                             include_top = False, \n",
        "                                             input_tensor = input)\n",
        "# Now that we apply global max pooling.\n",
        "gap = tf.keras.layers.GlobalMaxPooling2D()(efnet.output)\n",
        "\n",
        "# Finally, we add a classification layer.\n",
        "#gap = tf.keras.layers.Dense(3136, activation='relu', use_bias=True)(gap)\n",
        "\n",
        "\n",
        "gap = Dense(52, activation = 'relu')(gap)\n",
        "gap = Dropout(0.2)(gap)\n",
        "\n",
        "output = concatenate([gap, predict])\n",
        "output = Dense(52, activation = 'relu')(output)\n",
        "output = Dropout(0.2)(output)\n",
        "output = Dense(26,activation = 'softmax')(output)\n",
        "# bind all\n",
        "func_model = tf.keras.Model(inputs=[input,char_inputs], outputs=[output])\n",
        "func_model.compile(\n",
        "          loss  = tf.keras.losses.CategoricalCrossentropy(),\n",
        "          metrics = tf.keras.metrics.CategoricalAccuracy(),\n",
        "          optimizer = tf.keras.optimizers.Adam())"
      ],
      "metadata": {
        "id": "A4r1qFtHBxJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "func_model.summary()"
      ],
      "metadata": {
        "id": "1BIMNdyV6J_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdc = np.array(predict_train.iloc[:,1:])"
      ],
      "metadata": {
        "id": "3xgTP6-nDN6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습"
      ],
      "metadata": {
        "id": "iRTVL26DZjxF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fit \n",
        "func_model.fit(train_data, train_data_class, batch_size=128, epochs=5, validation_split = 0.2, verbose = 1)"
      ],
      "metadata": {
        "id": "-DCc0D9FgZ2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 결과 확인"
      ],
      "metadata": {
        "id": "NAfBHDuvaCOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test 처리\n",
        "test_data =  np.array(test_data_list.iloc[:,1:])\n",
        "test_data = test_data.reshape(test_data.shape[0],28,28,1)\n",
        "test_data_class = np.array(test_data_list.iloc[:,0]) -1\n",
        "origin_test = test_data_class\n",
        "test_data_class = np_utils.to_categorical(test_data_class, class_size)\n",
        "\n",
        "print(test_data_class)"
      ],
      "metadata": {
        "id": "oSkCpUoMAWzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdctest = np.array(predict_test.iloc[:,1:])"
      ],
      "metadata": {
        "id": "sW9oGt-LEBGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LSTM 모델 실험\n",
        "score = func_model.evaluate(x=[test_data,pdctest],y= test_data_class, verbose=0)\n",
        "\n",
        "print(\"loss : \" + str(score[0]))\n",
        "print(\"accuracy : \" + str(score[1]))"
      ],
      "metadata": {
        "id": "yM4QqcKmEFQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LSTM 모델 X 실험\n",
        "score = func_model.evaluate(x=test_data,y= test_data_class, verbose=0)\n",
        "\n",
        "print(\"loss : \" + str(score[0]))\n",
        "print(\"accuracy : \" + str(score[1]))"
      ],
      "metadata": {
        "id": "LphSQPc2sgah"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}